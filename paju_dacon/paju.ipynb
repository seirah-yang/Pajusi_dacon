{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d1a054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaco/anaconda3/envs/seirah/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, re, json, time\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API 키가 로드되었나요? True\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"API 키가 로드되었나요?\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "\n",
    "EMBED_MODEL = \"intfloat/e5-large\"\n",
    "GPT_MODEL = \"gpt-4-turbo\"\n",
    "NLI_MODEL = \n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "SAVE_DIR = \"./outputs\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfca7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2️⃣  문서 검색 (E5 임베딩 기반)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def search_reference(query: str, corpus: List[str], topk: int = 5):\n",
    "    q_emb = embedder.encode([query], normalize_embeddings=True)\n",
    "    c_emb = embedder.encode(corpus, normalize_embeddings=True)\n",
    "    sims = cosine_similarity(q_emb, c_emb)[0]\n",
    "    top_idx = np.argsort(sims)[::-1][:topk]\n",
    "    return [(corpus[i], float(sims[i])) for i in top_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9555e8",
   "metadata": {},
   "source": [
    "[Hybrid Retrieval Node] → [Form Node] → [Context Node]\n",
    "   ↓\n",
    "[Draft Node (GPT 생성)] → [Validate Node] → [Export Node] → [RPA Node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LLM + LangGraph Pipeline– Form → Context → Draft → Validate → Export\n",
    "# 행정문서 자동 생성·검증, 민원분류, 정책문 초안 작성(GPT-계열 LLM)\n",
    "# 3. GPT 기반 문서 생성\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "DOC_TEMPLATES = {\n",
    "    # 1️ 정책 제안서 (AI 기반 행정혁신, 시정 개선안 등)\n",
    "    \"policy_proposal\": {\n",
    "        \"system\": (\n",
    "            \"당신은 지방자치단체의 정책 기획 전문가입니다. \"\n",
    "            \"파주시의 데이터 기반 행정혁신 과제를 위한 정책 제안서를 작성하세요. \"\n",
    "            \"모든 문장은 공식 보고서 문체로, 객관적 근거와 수치에 기반하여 작성합니다.\"\n",
    "        ),\n",
    "        \"instructions\": [\n",
    "            \"요약(Executive Summary)을 맨 앞에 작성\",\n",
    "            \"정책 배경·현황 → 문제 정의 → 추진 필요성 → 제안 내용 → 기대효과 순서로 구성\",\n",
    "            \"근거 데이터(통계청·경기도 데이터드림·삼성카드 등) 출처를 명시\",\n",
    "            \"정책 추진 일정(연도별 단계)과 담당 부서를 제시\",\n",
    "            \"예상 재정소요와 효과를 정량화(단위: 백만원, 인원, % 등)\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # 2️ 내부 보고서 (부서장 보고용)\n",
    "    \"internal_report\": {\n",
    "        \"system\": (\n",
    "            \"당신은 파주시청 내부 업무보고 문서를 작성하는 행정 전문가입니다. \"\n",
    "            \"문서는 간결하되, 핵심 수치·추진 경과·차기 계획이 명확해야 합니다.\"\n",
    "        ),\n",
    "        \"instructions\": [\n",
    "            \"1페이지 이내 요약(핵심현황, 주요성과, 차기계획)을 먼저 제시\",\n",
    "            \"사업명·담당부서·담당자·기간·예산을 명확히 표기\",\n",
    "            \"성과와 문제점을 각각 3개 이내로 요약\",\n",
    "            \"차기 추진계획은 구체적 일정과 액션 담당자 포함\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # 3️ 사업계획서 (공모·예산 신청용)\n",
    "    \"business_plan\": {\n",
    "        \"system\": (\n",
    "            \"당신은 지자체 사업계획서 작성 전문가입니다. \"\n",
    "            \"파주시의 AI·데이터 기반 행정서비스 사업 제안서를 작성하세요.\"\n",
    "        ),\n",
    "        \"instructions\": [\n",
    "            \"기본 목차: 사업개요 → 추진배경 → 사업목표 → 세부 추진계획 → 예산계획 → 기대효과\",\n",
    "            \"예산은 인건비·운영비·시스템 구축비 등 세부 항목으로 분류\",\n",
    "            \"성과지표(KPI)는 정량적(예: 행정처리시간 20% 단축)으로 명시\",\n",
    "            \"리스크 요인과 대응전략을 포함\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # 4️ 의회 보고서 / 주요 업무계획\n",
    "    \"assembly_brief\": {\n",
    "        \"system\": (\n",
    "            \"당신은 시의회 보고용 행정 현안 문서를 작성하는 전문가입니다. \"\n",
    "            \"공식·격식 있는 문체로 주요 추진사항과 예산을 중심으로 보고서를 작성하세요.\"\n",
    "        ),\n",
    "        \"instructions\": [\n",
    "            \"개요 → 추진현황 → 문제점 및 개선계획 → 예산 및 일정 → 요청사항 순서로 구성\",\n",
    "            \"핵심 내용은 불릿(•) 형태로 정리\",\n",
    "            \"정책명·부서명·연도별 예산을 구체적으로 제시\",\n",
    "            \"결론부에는 의회의 협조 요청 또는 승인 요청 문구 포함\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # 5️ 행정 공문 (기관 간 협조요청, 보고 등)\n",
    "    \"official_letter\": {\n",
    "        \"system\": (\n",
    "            \"당신은 파주시청의 공문 작성 전문가입니다. \"\n",
    "            \"공문은 수신처·제목·본문·첨부·발신자(직위) 형식을 준수하며 \"\n",
    "            \"공식·간결한 어조로 작성해야 합니다.\"\n",
    "        ),\n",
    "        \"instructions\": [\n",
    "            \"수신·참조·제목·본문·첨부·발신자 순서로 작성\",\n",
    "            \"본문은 3단락 이내(요약, 협조요청내용, 추가문의)\",\n",
    "            \"정책명·기간·협조범위는 구체적으로 명시\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # 6️ 기술보고서 (AI/데이터 분석 결과 보고)\n",
    "    \"technical_report\": {\n",
    "        \"system\": (\n",
    "            \"당신은 데이터 기반 행정분석 보고서를 작성하는 데이터사이언티스트입니다. \"\n",
    "            \"파주시 관련 데이터를 분석한 결과를 객관적으로 정리하세요.\"\n",
    "        ),\n",
    "        \"instructions\": [\n",
    "            \"목차: 분석배경 → 데이터 개요 → 분석방법 → 주요결과(표/그래프 설명) → 시사점\",\n",
    "            \"수치·모델명·데이터기간 등은 구체적으로 표기\",\n",
    "            \"시사점은 정책 적용 가능성과 한계(리미트) 포함\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # 7️ 민원 요약 및 분류 보고서\n",
    "    \"civil_complaint_report\": {\n",
    "        \"system\": (\n",
    "            \"당신은 민원 데이터를 분석해 분류·요약 보고서를 작성하는 행정데이터 전문가입니다. \"\n",
    "            \"AI 기반 민원 자동 분류 결과를 행정용 요약문으로 정리하세요.\"\n",
    "        ),\n",
    "        \"instructions\": [\n",
    "            \"민원 유형별(교통·환경·복지 등) 주요 빈도와 트렌드 제시\",\n",
    "            \"지역별(읍면동 단위) 상위 3개 민원 이슈 표로 정리\",\n",
    "            \"유형별 개선방안 제시(담당 부서/조치기한 포함)\",\n",
    "            \"데이터 출처(민원시스템, 접수기간 등) 명기\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # 8️ 보도자료 / 시민 안내문\n",
    "    \"press_release\": {\n",
    "        \"system\": (\n",
    "            \"당신은 파주시 홍보담당관실의 보도자료 작성 전문가입니다. \"\n",
    "            \"시민이 쉽게 이해할 수 있도록 명료한 문체로 작성하세요.\"\n",
    "        ),\n",
    "        \"instructions\": [\n",
    "            \"헤드라인·리드문(핵심 메시지) → 본문(내용·시행시기) → 문의처 순서\",\n",
    "            \"전문용어 대신 쉬운 표현 사용\",\n",
    "            \"핵심 통계(예: 참여인원, 지원금액)는 구체적으로 제시\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # 9 회의록 (내부 간담회·정책협의)\n",
    "    \"minutes\": {\n",
    "        \"system\": (\n",
    "            \"당신은 행정회의록을 작성하는 비서관입니다. \"\n",
    "            \"모든 발언은 요약·객관적으로 기록하고, 결정사항과 담당자를 명확히 하세요.\"\n",
    "        ),\n",
    "        \"instructions\": [\n",
    "            \"회의명·일시·참석자·주요안건을 상단에 표기\",\n",
    "            \"논의내용은 요약하되, 핵심결정 및 조치사항을 별도 항목으로 정리\",\n",
    "            \"각 조치사항에는 담당부서·책임자·기한을 명시\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def build_prompt(section_name: str, references: str, constraints: List[str], doc_type: str):\n",
    "    base_rules = [\n",
    "        \"근거 불명 정보는 금지합니다. 출처를 명기하세요.\",\n",
    "        \"수치·정책명·기간 등은 가능한 한 구체적으로 제시하세요.\",\n",
    "        \"문장은 보고서 수준의 완결된 형태로 유지하세요.\"\n",
    "    ]\n",
    "    template = DOC_TEMPLATES.get(doc_type)\n",
    "    if template:\n",
    "        system_role = template[\"system\"]\n",
    "        doc_instructions = template[\"instructions\"]\n",
    "    else:\n",
    "        system_role = \"당신은 행정문서 작성 전문가입니다. 객관적이고 근거기반으로 작성하세요.\"\n",
    "        doc_instructions = []\n",
    "\n",
    "    all_constraints = base_rules + doc_instructions + constraints\n",
    "\n",
    "    # 모델에게 구조화(JSON) 응답을 요청 (파싱 용이)\n",
    "    user_prompt = f\"\"\"\n",
    "# 작성항목: [{section_name}]\n",
    "# 문서유형: [{doc_type}]\n",
    "# 작성조건: {', '.join(all_constraints)}\n",
    "# 참고자료:\n",
    "{references}\n",
    "\n",
    "다음 기준에 맞춰 내용을 생성하세요:\n",
    "1) 출력 형식: **JSON**. 키는 아래와 같아야 합니다:\n",
    "   {{\n",
    "     \"summary\": \"한 문단(요약)\",\n",
    "     \"body\": \"상세 본문(여러 문단 가능)\",\n",
    "     \"recommendations\": [{{{{\"title\":\"\", \"detail\":\"\", \"impact_estimate\":\"(예: 연간 비용/효과)\"}}}}],\n",
    "     \"action_items\": [{{{{\"task\":\"\", \"owner\":\"\", \"due\":\"YYYY-MM-DD\"}}}}],\n",
    "     \"references\": [\"출처1(기관, 연도)\", \"출처2(링크/문헌)\"]\n",
    "   }}\n",
    "2) 각 주장 옆에 간단한 출처 주석을 괄호형태로 표기하세요 (예: (통계청, 2023)).\n",
    "3) 표나 수치가 필요하면 간단한 표/항목 리스트로 제시하세요.\n",
    "4) 문체: 한국어 보고서 문체(공식적).\n",
    "\"\"\"\n",
    "\n",
    "    return system_role, user_prompt\n",
    "\n",
    "def _truncate_references(references: str, max_chars: int = 6000) -> str:\n",
    "    if len(references) <= max_chars:\n",
    "        return references\n",
    "    # 안전하게 문장 단위로 자르기\n",
    "    truncated = references[:max_chars]\n",
    "    last_period = truncated.rfind(\"\\n\")\n",
    "    if last_period > 0:\n",
    "        truncated = truncated[:last_period]\n",
    "    truncated += \"\\n\\n[참고: 원문이 너무 김 - 일부만 제공됨]\"\n",
    "    return truncated\n",
    "\n",
    "def _validate_output(parsed: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
    "    errors = []\n",
    "    required_keys = [\"summary\", \"body\", \"recommendations\", \"references\"]\n",
    "    for k in required_keys:\n",
    "        if k not in parsed:\n",
    "            errors.append(f\"Missing key: {k}\")\n",
    "\n",
    "    # 숫자 포맷 체크 예시: 권고안 impact_estimate\n",
    "    if \"recommendations\" in parsed:\n",
    "        for i, r in enumerate(parsed[\"recommendations\"]):\n",
    "            if \"impact_estimate\" in r and r[\"impact_estimate\"]:\n",
    "                # 간단 숫자 존재 확인 (숫자 또는 원화 표기)\n",
    "                if not re.search(r\"\\d\", str(r[\"impact_estimate\"])):\n",
    "                    errors.append(f\"recommendations[{i}].impact_estimate에 숫자가 포함되어야 합니다.\")\n",
    "\n",
    "    # references 최소 1개 이상\n",
    "    if \"references\" in parsed and len(parsed[\"references\"]) == 0:\n",
    "        errors.append(\"references는 하나 이상 필요합니다.\")\n",
    "\n",
    "    return (len(errors) == 0), errors\n",
    "\n",
    "def gpt_generate(\n",
    "    section_name: str,\n",
    "    references: str,\n",
    "    constraints: List[str],\n",
    "    doc_type: str = \"internal_report\",\n",
    "    temperature: float = None,\n",
    "    max_tokens: int = 1200,\n",
    "    retries: int = 3\n",
    ") -> Dict[str, Any]:\n",
    "    # doc_type별 권장 온도(있으면 사용)\n",
    "    temp_map = {\n",
    "        \"policy_proposal\": 0.2,\n",
    "        \"internal_report\": 0.1,\n",
    "        \"official_letter\": 0.0,\n",
    "        \"business_plan\": 0.2,\n",
    "        \"technical_report\": 0.1,\n",
    "        \"press_release\": 0.3,\n",
    "        \"minutes\": 0.0\n",
    "    }\n",
    "    if temperature is None:\n",
    "        temperature = temp_map.get(doc_type, 0.2)\n",
    "\n",
    "    # references 길이 조절\n",
    "    safe_references = _truncate_references(references, max_chars=5000)\n",
    "\n",
    "    system_role, user_prompt = build_prompt(section_name, safe_references, constraints, doc_type)\n",
    "\n",
    "    attempt = 0\n",
    "    last_exc = None\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            res = client.chat.completions.create(\n",
    "                model=GPT_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_role},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "            text = res.choices[0].message.content.strip()\n",
    "\n",
    "            try:\n",
    "                parsed = json.loads(text)\n",
    "            except json.JSONDecodeError:\n",
    "                # 모델이 코드블록 등으로 감싸진 경우 정리\n",
    "                # ```json\\n{...}\\n``` 제거 시도\n",
    "                m = re.search(r\"```(?:json)?\\s*(\\{.*\\})\\s*```\", text, re.DOTALL)\n",
    "                if m:\n",
    "                    payload = m.group(1)\n",
    "                    parsed = json.loads(payload)\n",
    "                else:\n",
    "                    # fallback: 텍스트를 body로 넣어 최소 출력 보장\n",
    "                    parsed = {\n",
    "                        \"summary\": \"\",\n",
    "                        \"body\": text,\n",
    "                        \"recommendations\": [],\n",
    "                        \"action_items\": [],\n",
    "                        \"references\": []\n",
    "                    }\n",
    "\n",
    "            # 기본 검증 수행\n",
    "            ok, errors = _validate_output(parsed)\n",
    "            if not ok:\n",
    "                # 검증 실패 시 모델에 재요청(간단 리피드)\n",
    "                # 여기서는 오류를 기록하고 재시도하도록 함\n",
    "                attempt += 1\n",
    "                last_exc = Exception(f\"Output validation failed: {errors}\")\n",
    "                time.sleep(1 + attempt * 1.5)\n",
    "                continue\n",
    "\n",
    "            # 메타 추가\n",
    "            parsed[\"_meta\"] = {\n",
    "                \"model\": GPT_MODEL,\n",
    "                \"temperature\": temperature,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"generated_at\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "            }\n",
    "            return parsed\n",
    "\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            attempt += 1\n",
    "            backoff = 1.5 ** attempt\n",
    "            time.sleep(backoff)\n",
    "            continue\n",
    "\n",
    "    # 모든 시도 실패 시 예외 발생\n",
    "    raise RuntimeError(f\"gpt_generate failed after {retries} attempts. last error: {last_exc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af9dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/alpaco/homework/paju_dacon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2b2d33",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mGPT_UNIEVAL_NLI_Pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_pipeline\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m하이브리드 검색을 통해 행정문서 자동화를 위한 규정/서식 요건을 통합\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m도입 배경 및 필요성\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m행정 자동화 기획서\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m근거 기반\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m중복 최소화\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m정량적 수치 포함\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUNIEVAL 기준 준수\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/alpaco/homework/paju_dacon/corpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/alpaco/homework/paju_dacon/outputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Notebook에 그래프 즉시 표시\u001b[39;00m\n",
      "File \u001b[0;32m~/homework/paju_dacon/GPT_UNIEVAL_NLI_Pipeline.py:334\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(query, section_name, doc_type, constraints, corpus_dir, out_dir)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/homework/paju_dacon/GPT_UNIEVAL_NLI_Pipeline.py:96\u001b[0m, in \u001b[0;36mTextCorpus.add_pdf\u001b[0;34m(self, file_path, chunk_size, overlap)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_pdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m, overlap: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m     95\u001b[0m     reader \u001b[38;5;241m=\u001b[39m PdfReader(file_path)\n\u001b[0;32m---> 96\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     text \u001b[38;5;241m=\u001b[39m normalize_text(text)\n\u001b[1;32m     98\u001b[0m     doc_id \u001b[38;5;241m=\u001b[39m Path(file_path)\u001b[38;5;241m.\u001b[39mstem\n",
      "File \u001b[0;32m~/homework/paju_dacon/GPT_UNIEVAL_NLI_Pipeline.py:96\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_pdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m, overlap: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m     95\u001b[0m     reader \u001b[38;5;241m=\u001b[39m PdfReader(file_path)\n\u001b[0;32m---> 96\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mpages)\n\u001b[1;32m     97\u001b[0m     text \u001b[38;5;241m=\u001b[39m normalize_text(text)\n\u001b[1;32m     98\u001b[0m     doc_id \u001b[38;5;241m=\u001b[39m Path(file_path)\u001b[38;5;241m.\u001b[39mstem\n",
      "File \u001b[0;32m~/anaconda3/envs/seirah/lib/python3.10/site-packages/PyPDF2/_page.py:1851\u001b[0m, in \u001b[0;36mPageObject.extract_text\u001b[0;34m(self, Tj_sep, TJ_sep, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text, *args)\u001b[0m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orientations, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   1849\u001b[0m     orientations \u001b[38;5;241m=\u001b[39m (orientations,)\n\u001b[0;32m-> 1851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONTENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/seirah/lib/python3.10/site-packages/PyPDF2/_page.py:1356\u001b[0m, in \u001b[0;36mPageObject._extract_text\u001b[0;34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     content \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1353\u001b[0m         obj[content_key]\u001b[38;5;241m.\u001b[39mget_object() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_key, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obj\n\u001b[1;32m   1354\u001b[0m     )\n\u001b[1;32m   1355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, ContentStream):\n\u001b[0;32m-> 1356\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[43mContentStream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbytes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:  \u001b[38;5;66;03m# it means no content can be extracted(certainly empty page)\u001b[39;00m\n\u001b[1;32m   1358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/seirah/lib/python3.10/site-packages/PyPDF2/generic/_data_structures.py:877\u001b[0m, in \u001b[0;36mContentStream.__init__\u001b[0;34m(self, stream, pdf, forced_encoding)\u001b[0m\n\u001b[1;32m    875\u001b[0m     stream_bytes \u001b[38;5;241m=\u001b[39m BytesIO(stream_data_bytes)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforced_encoding \u001b[38;5;241m=\u001b[39m forced_encoding\n\u001b[0;32m--> 877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__parse_content_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/seirah/lib/python3.10/site-packages/PyPDF2/generic/_data_structures.py:943\u001b[0m, in \u001b[0;36mContentStream.__parse_content_stream\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    941\u001b[0m         peek \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     operands\u001b[38;5;241m.\u001b[39mappend(\u001b[43mread_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforced_encoding\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/seirah/lib/python3.10/site-packages/PyPDF2/generic/_data_structures.py:1077\u001b[0m, in \u001b[0;36mread_object\u001b[0;34m(stream, pdf, forced_encoding)\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m IndirectObject\u001b[38;5;241m.\u001b[39mread_from_stream(stream, pdf)\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1077\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNumberObject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_from_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1079\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/seirah/lib/python3.10/site-packages/PyPDF2/generic/_base.py:406\u001b[0m, in \u001b[0;36mNumberObject.read_from_stream\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_from_stream\u001b[39m(stream: StreamType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberObject\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFloatObject\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    405\u001b[0m     num \u001b[38;5;241m=\u001b[39m read_until_regex(stream, NumberObject\u001b[38;5;241m.\u001b[39mNumberPattern)\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m FloatObject(num)\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NumberObject(num)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from GPT_UNIEVAL_NLI_Pipeline import run_pipeline\n",
    "run_pipeline(\n",
    "    query=\"하이브리드 검색을 통해 행정문서 자동화를 위한 규정/서식 요건을 통합\",\n",
    "    section_name=\"도입 배경 및 필요성\",\n",
    "    doc_type=\"행정 자동화 기획서\",\n",
    "    constraints=[\"근거 기반\", \"중복 최소화\", \"정량적 수치 포함\", \"UNIEVAL 기준 준수\"],\n",
    "    corpus_dir=\"/home/alpaco/homework/paju_dacon/corpus\",\n",
    "    out_dir=\"/home/alpaco/homework/paju_dacon/outputs\"\n",
    ")\n",
    "\n",
    "plt.show()  # Notebook에 그래프 즉시 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dce2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(\n",
    "    query=\"하이브리드 검색을 통해 행정문서 자동화를 위한 규정/서식 요건을 통합\",\n",
    "    section_name=\"도입 배경 및 필요성\",\n",
    "    doc_type=\"행정 자동화 기획서\",\n",
    "    constraints=[\"근거 기반\", \"중복 최소화\", \"정량적 수치 포함\", \"UNIEVAL 기준 준수\"],\n",
    "    corpus_dir=\"/home/alpaco/homework/paju_dacon/corpus\",\n",
    "    out_dir=\"/home/alpaco/homework/paju_dacon/outputs\"\n",
    ")\n",
    "\n",
    "plt.show()  # Notebook에 그래프 즉시 표시\n",
    "return bar_path, radar_path  # 경로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f670f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NLI 기반 Validator + UNIEVAL 평가 모듈\n",
    "# 행정기록의 위변조 방지 및 결재 이력 추적( 전자문서 이력관리·결재 로그 보안)\n",
    "# 4. GPT 기반 품질 평가\n",
    "def gpt_validate(section_name: str, draft_text: str):\n",
    "    prompt = f\"\"\"\n",
    "당신은 행정 문서 품질평가 전문가입니다.\n",
    "아래 작성문을 항목별로 평가해주세요.\n",
    "\n",
    "[평가기준]\n",
    "1. 정확성 (Accuracy) : 사실과 규정 근거의 일치 여부\n",
    "2. 연관성 (Relevance) : 제목과 내용의 일치 정도\n",
    "3. 일관성 (Consistency) : 수치·단위·논리의 균형\n",
    "4. 유창성 (Fluency) : 문장 구조와 표현의 자연스러움\n",
    "5. 중복도 (Redundancy↓) : 불필요 반복의 존재 여부\n",
    "\n",
    "출력형식(JSON):\n",
    "{{\n",
    "  \"Accuracy\": 0~1,\n",
    "  \"Relevance\": 0~1,\n",
    "  \"Consistency\": 0~1,\n",
    "  \"Fluency\": 0~1,\n",
    "  \"Redundancy\": 0~1,\n",
    "  \"Comment\": \"개선 의견 요약\"\n",
    "}}\n",
    "\n",
    "[평가대상: {section_name}]\n",
    "{draft_text}\n",
    "\"\"\"\n",
    "    res = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"당신은 평가전문가입니다.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    try:\n",
    "        data = json.loads(res.choices[0].message.content)\n",
    "    except Exception:\n",
    "        data = {\"Accuracy\": 0.7, \"Relevance\": 0.7, \"Consistency\": 0.7, \"Fluency\": 0.7, \"Redundancy\": 0.2, \"Comment\": \"형식적 오류 없음\"}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 DOCX Export + 클라우드 저장\n",
    "# (협업 행정 및 SaaS형 행정 서비스)\t\n",
    "# 문서 자동화 시스템을 클라우드형 워크스페이스로 확장\n",
    "def export_report(sections: List[Dict[str, Any]], out_path: str):\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"AI 기반 행정·R&D 문서 자동생성 보고서\", level=0)\n",
    "    doc.add_paragraph(f\"생성일시: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    for s in sections:\n",
    "        doc.add_heading(s[\"title\"], level=1)\n",
    "        doc.add_paragraph(s[\"draft\"])\n",
    "        doc.add_heading(\"품질평가\", level=2)\n",
    "        doc.add_paragraph(json.dumps(s[\"eval\"], ensure_ascii=False, indent=2))\n",
    "    doc.save(out_path)\n",
    "    print(f\"✅ 보고서 저장 완료: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.  메인 파이프라인\n",
    "def run_pipeline(sections_config: List[Dict[str, Any]], reference_corpus: List[str]):\n",
    "    all_sections = []\n",
    "    for sec in sections_config:\n",
    "        title = sec[\"section\"]\n",
    "        refs = search_reference(title, reference_corpus, topk=3)\n",
    "        ref_text = \"\\n\\n\".join([r[0] for r in refs])\n",
    "        draft = gpt_generate(title, ref_text, sec.get(\"constraints\", []))\n",
    "        eval_res = gpt_validate(title, draft)\n",
    "        all_sections.append({\n",
    "            \"title\": title,\n",
    "            \"draft\": draft,\n",
    "            \"eval\": eval_res\n",
    "        })\n",
    "        print(f\"[완료] {title} (평가점수: {eval_res})\")\n",
    "\n",
    "    out_path = os.path.join(SAVE_DIR, f\"RND_Report_{datetime.now().strftime('%Y%m%d_%H%M')}.docx\")\n",
    "    export_report(all_sections, out_path)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a92dd4a",
   "metadata": {},
   "source": [
    "### 스마트 행정 생태계는 다음과 같은 핵심 요소들로 구성됩니다.\n",
    "•\t첨단 기술 기반 시설: 센서, IoT 기기, 고속 통신망, 클라우드 시스템 등 기술적 기반이 필수적\n",
    "\n",
    "•\t데이터 통합 및 분석 플랫폼: 도시에서 발생하는 다양한 데이터를 수집, 통합, 분석하여 정책 수립과 의사결정에 활용하는 데이터 허브 역할\n",
    "\n",
    "•\t스마트 서비스: AI 챗봇을 활용한 24시간 민원 응대, 자율주행 셔틀, 스마트 환경 관리 솔루션 등 구체적인 시민 체감형 서비스가 포함\n",
    "\n",
    "•\t협력적 거버넌스: 민-관-학이 협력하여 도시 문제를 발굴하고 해결책을 모색하는 리빙랩(Living Lab) 방식의 운영 체계가 중요\n",
    "\n",
    "•\t인적 자산 및 제도: 변화에 대한 긍정적인 태도를 가진 행정 인력과 혁신을 지원하는 규제 개선(규제 샌드박스 등) 노력이 필요\n",
    " \n",
    "### 기대 효과 및 변화\n",
    "•\t행정 효율성 증대: 반복적인 업무를 자동화하고(AI 활용 문서 요약 등), 신속한 행정 처리를 가능\n",
    "\n",
    "•\t서비스 품질 향상: 시민들에게 맞춤형 서비스를 제공하고(스마트 돌봄 등), 민원 처리 속도와 만족도 높임\n",
    "\n",
    "•\t선제적 문제 해결: 데이터를 기반으로 사회 문제를 예측하고 선제적으로 대응\n",
    "\n",
    "  ➔ 재난 안전, 교통, 환경 등 다양한 분야의 도시 문제를 효과적으로 관리\n",
    "\n",
    "•\t지속가능한 도시 발전: 한정된 자원을 효율적으로 사용하여 에너지 절감 및 환경 보호에 기여하고, 지속가능한 도시 성장도모"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seirah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
